# -*- coding: utf-8 -*-
"""HarrWavelet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kDtT4mAPV73zwcFysOJ4Ju-zilTPP-5F
"""

import pywt
import cv2
import numpy as np
import os
import json
from google.colab import files
from zipfile import ZipFile
import io

def blur_detect(img, threshold):
    # Convert image to grayscale
    Y = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    M, N = Y.shape

    # Crop input image to be 3 divisible by 2
    Y = Y[0:int(M/16)*16, 0:int(N/16)*16]

    # Step 1, compute Haar wavelet of input image
    LL1,(LH1,HL1,HH1)= pywt.dwt2(Y, 'haar')
    # Another application of 2D haar to LL1
    LL2,(LH2,HL2,HH2)= pywt.dwt2(LL1, 'haar')
    # Another application of 2D haar to LL2
    LL3,(LH3,HL3,HH3)= pywt.dwt2(LL2, 'haar')

    # Construct the edge map in each scale Step 2
    E1 = np.sqrt(np.power(LH1, 2)+np.power(HL1, 2)+np.power(HH1, 2))
    E2 = np.sqrt(np.power(LH2, 2)+np.power(HL2, 2)+np.power(HH2, 2))
    E3 = np.sqrt(np.power(LH3, 2)+np.power(HL3, 2)+np.power(HH3, 2))

    M1, N1 = E1.shape

    # Sliding window size level 1
    sizeM1 = 8
    sizeN1 = 8

    # Sliding windows size level 2
    sizeM2 = int(sizeM1/2)
    sizeN2 = int(sizeN1/2)

    # Sliding windows size level 3
    sizeM3 = int(sizeM2/2)
    sizeN3 = int(sizeN2/2)

    # Number of edge maps, related to sliding windows size
    N_iter = int((M1/sizeM1)*(N1/sizeN1))

    Emax1 = np.zeros((N_iter))
    Emax2 = np.zeros((N_iter))
    Emax3 = np.zeros((N_iter))

    count = 0

    # Sliding windows index of level 1
    x1 = 0
    y1 = 0
    # Sliding windows index of level 2
    x2 = 0
    y2 = 0
    # Sliding windows index of level 3
    x3 = 0
    y3 = 0

    # Sliding windows limit on horizontal dimension
    Y_limit = N1-sizeN1

    while count < N_iter:
        # Get the maximum value of slicing windows over edge maps
        # in each level
        Emax1[count] = np.max(E1[x1:x1+sizeM1,y1:y1+sizeN1])
        Emax2[count] = np.max(E2[x2:x2+sizeM2,y2:y2+sizeN2])
        Emax3[count] = np.max(E3[x3:x3+sizeM3,y3:y3+sizeN3])

        # if sliding windows ends horizontal direction
        # move along vertical direction and resets horizontal
        # direction
        if y1 == Y_limit:
            x1 = x1 + sizeM1
            y1 = 0

            x2 = x2 + sizeM2
            y2 = 0

            x3 = x3 + sizeM3
            y3 = 0

            count += 1

        # windows moves along horizontal dimension
        else:
            y1 = y1 + sizeN1
            y2 = y2 + sizeN2
            y3 = y3 + sizeN3
            count += 1

    # Step 3
    EdgePoint1 = Emax1 > threshold
    EdgePoint2 = Emax2 > threshold
    EdgePoint3 = Emax3 > threshold

    # Rule 1 Edge Points
    EdgePoint = EdgePoint1 + EdgePoint2 + EdgePoint3

    n_edges = EdgePoint.shape[0]

    # Rule 2 Dirak-Structure or Astep-Structure
    DAstructure = (Emax1[EdgePoint] > Emax2[EdgePoint]) * (Emax2[EdgePoint] > Emax3[EdgePoint])

    # Rule 3 Roof-Structure or Gstep-Structure
    RGstructure = np.zeros((n_edges))

    for i in range(n_edges):
        if EdgePoint[i] == 1:
            if Emax1[i] < Emax2[i] and Emax2[i] < Emax3[i]:
                RGstructure[i] = 1

    # Rule 4 Roof-Structure
    RSstructure = np.zeros((n_edges))

    for i in range(n_edges):
        if EdgePoint[i] == 1:
            if Emax2[i] > Emax1[i] and Emax2[i] > Emax3[i]:
                RSstructure[i] = 1

    # Rule 5 Edge more likely to be in a blurred image
    BlurC = np.zeros((n_edges))

    for i in range(n_edges):
        if RGstructure[i] == 1 or RSstructure[i] == 1:
            if Emax1[i] < threshold:
                BlurC[i] = 1

    # Step 6
    Per = np.sum(DAstructure)/np.sum(EdgePoint)

    # Step 7
    if (np.sum(RGstructure) + np.sum(RSstructure)) == 0:
        BlurExtent = 100
    else:
        BlurExtent = np.sum(BlurC) / (np.sum(RGstructure) + np.sum(RSstructure))

    return Per, BlurExtent

def find_images(input_dir):
    extensions = [".jpg", ".png", ".jpeg"]
    for root, dirs, files in os.walk(input_dir):
        for file in files:
            if os.path.splitext(file)[1].lower() in extensions:
                yield os.path.join(root, file)

"""To test, put images in a folder and store path in **input_dir**"""

# Create a directory to extract images/content/blur
input_dir = '/content/nonblur'
os.makedirs(input_dir, exist_ok=True)



threshold = 35
MinZero = 0.001
results = []
blurred_count = 0

for input_path in find_images(input_dir):
    try:
        I = cv2.imread(input_path)
        per, blurext = blur_detect(I, threshold)
        if per < MinZero:
            classification = True
            blurred_count += 1
        else:
            classification = False
        results.append({"input_path": input_path, "per": per, "blur extent": blurext, "is blur": classification})
        print("{0}, Per: {1:.20f}, blur extent: {2:.3f}, is blur: {3}".format(input_path, per, blurext, classification))
    except Exception as e:
        print(e)
        pass

# Save results to a JSON file
# save_path = 'blur_detection_results.json'
# with open(save_path, 'w') as outfile:
#     json.dump(results, outfile, sort_keys=True, indent=4)
#     outfile.write("\n")

# print(f"Results saved to {save_path}")
# files.download(save_path)

# Print summary
total_images = len(results)
print(f"Total images processed: {total_images}")
print(f"Number of blurred images: {blurred_count}")
print(f"Number of non-blurred images: {total_images - blurred_count}")

import cv2
import os
import numpy as np
from google.colab import files

# Define paths
input_dir = '/content/images'  # Path to your images
output_dir = '/content/augmented_images'  # Path to save augmented images

# Create the output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)

# Define blurring functions
def apply_gaussian_blur(image, kernel_size):
    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)

def apply_motion_blur(image, kernel_size):
    kernel = np.zeros((kernel_size, kernel_size))
    kernel[int((kernel_size - 1) / 2), :] = np.ones(kernel_size)
    kernel = kernel / kernel_size
    return cv2.filter2D(image, -1, kernel)

def apply_median_blur(image, kernel_size):
    return cv2.medianBlur(image, kernel_size)

# Function to augment images
def augment_image(image_path, output_dir, filename):
    # Read the image
    image = cv2.imread(image_path)

    # Apply different types of blur
    gaussian_blurred = apply_gaussian_blur(image, 15)
    motion_blurred = apply_motion_blur(image, 15)
    median_blurred = apply_median_blur(image, 15)

    # Save the augmented images
    cv2.imwrite(os.path.join(output_dir, filename.replace('.jpg', '_gaussian.jpg')), gaussian_blurred)
    cv2.imwrite(os.path.join(output_dir, filename.replace('.jpg', '_motion.jpg')), motion_blurred)
    cv2.imwrite(os.path.join(output_dir, filename.replace('.jpg', '_median.jpg')), median_blurred)
    cv2.imwrite(os.path.join(output_dir, filename.replace('.jpg', '_original.jpg')), image)

# Find all image files
extensions = [".jpg", ".jpeg", ".png"]
image_files = [f for f in os.listdir(input_dir) if os.path.splitext(f)[1].lower() in extensions]

# Loop through each image and augment
for image_file in image_files:
    image_path = os.path.join(input_dir, image_file)
    augment_image(image_path, output_dir, image_file)

print("Image augmentation complete.")

# Optionally, download the augmented images
!zip -r augmented_images.zip /content/augmented_images
files.download('augmented_images.zip')